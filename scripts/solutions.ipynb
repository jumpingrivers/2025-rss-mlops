{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59f33e2b",
   "metadata": {},
   "source": [
    "# Solutions\n",
    "\n",
    "\n",
    "## Task 1\n",
    "\n",
    "\n",
    "Context: It is 2005. The World Health Organisation (WHO) has just released the latest data on life expectancy stratified by country and year.\n",
    "\n",
    "a) Run the code cell below to load the `life_expectancy.csv` data set into a Pandas `DataFrame` called `data`. We also filter it so that it only contains data from _before_ 2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa0df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Your Q1a) code here\n",
    "data_full = pd.read_csv(\"./life_expectancy.csv\")\n",
    "data = data_full.loc[data_full[\"Year\"] < 2005]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065684a2",
   "metadata": {},
   "source": [
    "For now we will only be working with our `data` variable. We will return to our `data_full` variable later on (after some time has passed...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a2c6ad",
   "metadata": {},
   "source": [
    "b) The code below uses the `janitor` package to rename the columns in a neater format. Add an extra line to drop any rows containing missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca19ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import janitor\n",
    "\n",
    "\n",
    "data = data.clean_names(strip_underscores=True)\n",
    "# Your Q1b) code here\n",
    "data.dropna(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f8f60d",
   "metadata": {},
   "source": [
    "We will try to predict the life expectancy using the percentage expenditure, total expenditure, population, body-mass index (BMI) and schooling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fc312f",
   "metadata": {},
   "source": [
    "c) Run the code cell below to select the features (`X`) and the target (`y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12510726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code cell\n",
    "X = data[[\n",
    "    \"percentage_expenditure\",\n",
    "    \"total_expenditure\",\n",
    "    \"population\",\n",
    "    \"bmi\",\n",
    "    \"schooling\",\n",
    "]]\n",
    "y = data[\"life_expectancy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267aeec7",
   "metadata": {},
   "source": [
    "Now split the data into train and test sets, with 80% of the data going into the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb0dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db193ba",
   "metadata": {},
   "source": [
    "## Task 2: Modelling\n",
    "\n",
    "We will fit a $K$-Nearest Neighbour Regression model (`KNeighborsRegressor()` in sklearn).\n",
    "\n",
    "d) Set up a model pipeline in sklearn which includes:\n",
    "\n",
    "- Data preprocessing using a `StandardScaler`.\n",
    "- Modelling using `KNeighborsRegressor`.\n",
    "\n",
    "Fit your model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b588626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model = Pipeline(\n",
    "    [\n",
    "        (\"transform\", StandardScaler()),\n",
    "        (\"model\", KNeighborsRegressor()),\n",
    "    ]\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cfe211",
   "metadata": {},
   "source": [
    "e) Generate model predictions for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b7f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca5272f",
   "metadata": {},
   "source": [
    "f) Compute the root-mean-square error using the predicted and true values of the test data.\n",
    "\n",
    "_Hint: use the `sklearn.metrics.mean_squared_error` function to generate the mean squared error._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c10f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "mean_squared_error(y_test, y_pred) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd010fc",
   "metadata": {},
   "source": [
    "g) Create a `VetiverModel` instance using your trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c94775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vetiver\n",
    "\n",
    "\n",
    "v_model = vetiver.VetiverModel(\n",
    "    model,\n",
    "    model_name=\"k-nn\",\n",
    "    description=\"life-expectancy\",\n",
    "    prototype_data=X_test,\n",
    ")\n",
    "print(v_model.description)\n",
    "print(v_model.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db8308",
   "metadata": {},
   "source": [
    "## Task 3: Deploying your model\n",
    "\n",
    "\n",
    "h) Deploy your model to the localhost using a FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2860b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vetiver import VetiverAPI\n",
    "\n",
    "\n",
    "app = VetiverAPI(v_model, check_prototype=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4818a5d",
   "metadata": {},
   "source": [
    "i) Try running the code cell below to inspect your API in the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344b93e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run(port = 8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cfa870",
   "metadata": {},
   "source": [
    "j) Predict the life expectancy for the following inputs:\n",
    "\n",
    "- `percentage_expenditure`: 46\n",
    "- `total_expenditure`: 9\n",
    "- `population`: 5000000\n",
    "- `bmi`: 64\n",
    "- `schooling`: 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061940ec",
   "metadata": {},
   "source": [
    "k) If working locally, try opening a separate terminal and check that you can run the query programmatcally:\n",
    "\n",
    "```\n",
    "from vetiver.server import predict, vetiver_endpoint\n",
    "\n",
    "\n",
    "endpoint = vetiver_endpoint(\"http://127.0.0.1:8080/predict\")\n",
    "\n",
    "test_dict = {\n",
    "    \"percentage_expenditure\": [46],\n",
    "    \"total_expenditure\": [9],\n",
    "    \"population\": [5000000],\n",
    "    \"bmi\": [64]\n",
    "    \"schooling\": [20]\n",
    "}\n",
    "test_data = pd.DataFrame(test_dict)\n",
    "predict(endpoint, test_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5070e73",
   "metadata": {},
   "source": [
    "## Task 4: Detecting model drift\n",
    "\n",
    "How time flies: it is now 2010!\n",
    "\n",
    "l) Run the code cell below to load the data from 2005 to 2009, and drop missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d4d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code cell\n",
    "data_latest = data_full.loc[\n",
    "    (data_full[\"Year\"] >= 2005) &\n",
    "    (data_full[\"Year\"] <= 2009)\n",
    "]\n",
    "data_latest = data_latest.clean_names(strip_underscores=True)\n",
    "data_latest.dropna(inplace=True)\n",
    "data_latest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6346151a",
   "metadata": {},
   "source": [
    "m) Predict the life expectancy for this data using your pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a765e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_latest[[\n",
    "    \"percentage_expenditure\",\n",
    "    \"total_expenditure\",\n",
    "    \"population\",\n",
    "    \"bmi\",\n",
    "    \"schooling\",\n",
    "]]\n",
    "y = data_latest[\"life_expectancy\"]\n",
    "# Your m) code here\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a70c154",
   "metadata": {},
   "source": [
    "n) Now compute the RMSE. How does it compare with the value computed in part f) above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c68978",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y, y_pred) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b3abec",
   "metadata": {},
   "source": [
    "o) You should find that your model is not quite as accurate as it used to be. Retrain it using data from 2005 to 2009, remembering to split the data into train and test sets before you begin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1694b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fb1426",
   "metadata": {},
   "source": [
    "p) Now compute the new RMSE using the unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10648c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mean_squared_error(y_test, y_pred) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ddb72",
   "metadata": {},
   "source": [
    "You should find that by retraining your model on the latest data, you have mitigated the effects of data drift and reduced the model error. An MLOps workflow is designed to automate this process by continually monitoring the model predictions and retraining the model on a schedule."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rss-vetiver",
   "language": "python",
   "name": "rss-vetiver"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
